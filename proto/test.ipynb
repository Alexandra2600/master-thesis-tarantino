{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import add_data\n",
    "import utility_function\n",
    "import nest_asyncio\n",
    "import RAGAStest\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../tests/data/profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Mateo\"\n",
    "path_data_profiles = \"../tests/data/profiles/\"\n",
    "path_data_context = \"../tests/data/context/\"\n",
    "path_data_qa = \"../tests/data/qa/\"\n",
    "path_data_results = \"../tests/data/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorso del file CSV\n",
    "csv_filename = user + \".csv\"\n",
    "\n",
    "# Leggere il file CSV\n",
    "df = pd.read_csv(path_data_profiles + csv_filename)\n",
    "\n",
    "# Stampa delle prime righe per verificare il contenuto\n",
    "print(df.head())\n",
    "\n",
    "# Estrazione delle informazioni principali\n",
    "def extract_data(df):\n",
    "    for index, row in df.iterrows():\n",
    "        print(f\"Date: {row['date']}\")\n",
    "        print(f\"User: {row['user']}\")\n",
    "        print(f\"Input: {row['interaction']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Eseguire l'estrazione\n",
    "extract_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#costo 0,01 (30 interazioni)\n",
    "interactions = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    input = utility_function.process_text(text=row['interaction'], user_name=row['user'], current_date=row['date'])\n",
    "    interactions.append(input)\n",
    "\n",
    "context_df = pd.DataFrame(interactions)\n",
    "context_df.to_csv(path_data_context + user + \"_context.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_function.clean_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#costo: 0,02 (aggiunta di 30 input + resolver)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#Adding data to the graph\n",
    "for input in interactions:\n",
    "    response = await add_data.add_data_to_graph(input)\n",
    "    print(response)\n",
    "    \n",
    "#Resolving entities\n",
    "nest_asyncio.apply()\n",
    "res = await add_data.resolve_entities()\n",
    "print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiunta singola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "print(interactions[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await add_data.add_data_to_graph(interactions[n])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await add_data.resolve_entities()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add indexes to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_function.add_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esecuzione test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#costo 0.02*2 (10 domande)\n",
    "results_graphRAG = []\n",
    "results_RAG = []\n",
    "\n",
    "with open(path_data_qa + user + \"_qa.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "    graphRAG = RAGAStest.run_tests(dataset)\n",
    "    print(\"GraphRAG: \", graphRAG)\n",
    "    results_graphRAG.append({'user': user, 'results': graphRAG})\n",
    "    \n",
    "    RAG = RAGAStest.run_tests_RAG(dataset)\n",
    "    print(\"RAG: \", RAG)\n",
    "    results_RAG.append({'user': user, 'results': RAG})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stampa risultati su file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_graphRAG = pd.DataFrame(results_graphRAG)\n",
    "df_graphRAG.to_csv(path_data_results + \"results_graphRAG.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "df_RAG = pd.DataFrame(results_RAG)\n",
    "df_RAG.to_csv(path_data_results + \"results_RAG.csv\", mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_graphRAG)\n",
    "print(results_RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_graphRAG = results_graphRAG[0]['results'].scores\n",
    "res_RAG = results_RAG[0]['results'].scores\n",
    "\n",
    "print(res_graphRAG)\n",
    "print(res_RAG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generazione grafici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico singolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Conversione a DataFrame\n",
    "df_graphRAG = pd.DataFrame(res_graphRAG)\n",
    "df_RAG = pd.DataFrame(res_RAG)\n",
    "\n",
    "# Calcolo medie\n",
    "mean_graphRAG = df_graphRAG.mean()\n",
    "mean_RAG = df_RAG.mean()\n",
    "\n",
    "# Unione per confronto\n",
    "comparison_df = pd.DataFrame({\n",
    "    'GraphRAG': mean_graphRAG,\n",
    "    'RAG': mean_RAG\n",
    "})\n",
    "\n",
    "# Stampa dei valori medi\n",
    "print(\"Confronto delle medie tra GraphRAG e RAG:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Plot confronto\n",
    "comparison_df.plot(kind='bar', figsize=(10, 6), rot=45)\n",
    "plt.title('Confronto Medie Metriche tra GraphRAG e RAG')\n",
    "plt.ylabel('Valore medio')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../tests/data/results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico complessivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "CSV_GRAPH   = Path(\"../tests/data/results/results_graphRAG.csv\")   \n",
    "CSV_RAG     = Path(\"../tests/data/results/results_RAG.csv\")       \n",
    "\n",
    "COLOR_GRAPH = \"#0f8b8d\"   \n",
    "COLOR_RAG   = \"#07435d\"   \n",
    "BAR_WIDTH   = 0.30       \n",
    "\n",
    "METRIC_LABELS = {                         \n",
    "    \"llm_context_precision_with_reference\": \"Context precision\",\n",
    "    \"context_recall\":                      \"Context recall\",\n",
    "    \"answer_relevancy\":                    \"Answer relevancy\",\n",
    "    \"faithfulness\":                        \"Faithfulness\",\n",
    "    \"semantic_similarity\":                 \"Answer similarity\",\n",
    "}\n",
    "\n",
    "TITLE   = \"GraphRAG vs RAG\"  \n",
    "YLABEL  = \"Mean value\"        \n",
    "ANNOTATE_BARS = True                   \n",
    "\n",
    "\n",
    "def load_metrics(csv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carica il CSV con la forma:\n",
    "        NomeProfilo,\"{'metricA': 0.5, 'metricB': 0.7, ...}\"\n",
    "    e restituisce un DataFrame largo:\n",
    "        index = profili, colonne = metriche numeriche\n",
    "    \"\"\"\n",
    "    raw = pd.read_csv(\n",
    "        csv_path,\n",
    "        header=None,\n",
    "        names=[\"profile\", \"metrics_str\"],\n",
    "        quotechar='\"',\n",
    "        skipinitialspace=True,\n",
    "        engine=\"python\",           \n",
    "    )\n",
    "    \n",
    "    expanded = (\n",
    "        raw[\"metrics_str\"]\n",
    "        .apply(ast.literal_eval)    \n",
    "        .apply(pd.Series)\n",
    "    )\n",
    "    expanded.index = raw[\"profile\"]\n",
    "    return expanded\n",
    "\n",
    "\n",
    "def bar_labels(ax, bars):\n",
    "    \"\"\"Scrive il valore in cima a ogni barra.\"\"\"\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(\n",
    "            f\"{height:.2f}\",\n",
    "            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "            xytext=(0, 4),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "df_graph = load_metrics(CSV_GRAPH)\n",
    "df_rag   = load_metrics(CSV_RAG)\n",
    "\n",
    "mean_graph = df_graph.mean().rename(\"GraphRAG\")\n",
    "mean_rag   = df_rag.mean().rename(\"RAG\")\n",
    "\n",
    "comparison = pd.DataFrame([mean_graph, mean_rag]).T\n",
    "comparison.index.name = \"Metric\"\n",
    "print(\"\\nConfronto delle medie:\")\n",
    "print(comparison.round(4))\n",
    "print()\n",
    "\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 11,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.spines.top\":   False,\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics = list(METRIC_LABELS.keys())\n",
    "labels  = [METRIC_LABELS[m] for m in metrics]\n",
    "x       = np.arange(len(metrics))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "bars_graph = ax.bar(\n",
    "    x - BAR_WIDTH / 2,\n",
    "    comparison.loc[metrics, \"GraphRAG\"],\n",
    "    BAR_WIDTH,\n",
    "    label=\"GraphRAG\",\n",
    "    color=COLOR_GRAPH,\n",
    ")\n",
    "bars_rag = ax.bar(\n",
    "    x + BAR_WIDTH / 2,\n",
    "    comparison.loc[metrics, \"RAG\"],\n",
    "    BAR_WIDTH,\n",
    "    label=\"RAG\",\n",
    "    color=COLOR_RAG,\n",
    ")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=20, ha=\"right\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(TITLE, pad=15, weight=\"bold\")\n",
    "ax.set_ylabel(YLABEL)\n",
    "ax.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "if ANNOTATE_BARS:\n",
    "    bar_labels(ax, list(bars_graph) + list(bars_rag))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "CSV_GRAPH   = Path(\"../tests/data/results/results_graphRAG.csv\")   \n",
    "CSV_RAG     = Path(\"../tests/data/results/results_RAG.csv\")    \n",
    "\n",
    "METRIC_ORDER = [                      \n",
    "    (\"llm_context_precision_with_reference\", \"Context precision\"),\n",
    "    (\"context_recall\",                  \"Context recall\"),\n",
    "    (\"answer_relevancy\",                \"Answer relevancy\"),\n",
    "    (\"faithfulness\",                    \"Faithfulness\"),\n",
    "    (\"semantic_similarity\",             \"Answer similarity\"),\n",
    "]\n",
    "CMAP = \"viridis\"                       \n",
    "TITLE = \"Δ (GraphRAG – RAG) per profile/metric\"  \n",
    "OUTFILE = \"heatmap_delta.pdf\"          \n",
    "\n",
    "\n",
    "def load_metrics(csv_path: Path) -> pd.DataFrame:\n",
    "    raw = pd.read_csv(\n",
    "        csv_path,\n",
    "        header=None,\n",
    "        names=[\"profile\", \"metrics_str\"],\n",
    "        quotechar='\"',\n",
    "        skipinitialspace=True,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "    expanded = raw[\"metrics_str\"].apply(ast.literal_eval).apply(pd.Series)\n",
    "    expanded.index = raw[\"profile\"]\n",
    "    return expanded\n",
    "\n",
    "\n",
    "df_graph = load_metrics(CSV_GRAPH)\n",
    "df_rag   = load_metrics(CSV_RAG)\n",
    "\n",
    "delta = df_graph - df_rag       \n",
    "\n",
    "row_order = delta.mean(axis=1).sort_values(ascending=False).index\n",
    "delta = delta.loc[row_order]\n",
    "\n",
    "col_order = delta.mean(axis=0).sort_values(ascending=False).index\n",
    "delta = delta[col_order]\n",
    "\n",
    "\n",
    "metric_labels = [METRIC_LABELS[c] for c in delta.columns]\n",
    "profiles = delta.index.tolist()\n",
    "values   = delta.values\n",
    "                        \n",
    "\n",
    "plt.rcParams.update({\"font.size\": 10, \"axes.spines.top\": False,\n",
    "                     \"axes.spines.right\": False})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(metric_labels)*1.6, len(profiles)*0.45 + 1))\n",
    "im = ax.imshow(values, cmap=CMAP, aspect=\"auto\")\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(len(metric_labels)))\n",
    "ax.set_xticklabels(metric_labels, rotation=20, ha=\"right\")\n",
    "ax.set_yticks(np.arange(len(profiles)))\n",
    "ax.set_yticklabels(profiles)\n",
    "ax.set_title(TITLE, weight=\"bold\", pad=12)\n",
    "\n",
    "ax.set_xticks(np.arange(-.5, len(metric_labels), 1), minor=True)\n",
    "ax.set_yticks(np.arange(-.5, len(profiles), 1), minor=True)\n",
    "ax.grid(which=\"minor\", linestyle=\":\", linewidth=0.4)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.ax.set_ylabel(\"Δ score\", rotation=270, labelpad=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if OUTFILE:\n",
    "    fig.savefig(OUTFILE)\n",
    "    print(f\"Figura salvata in {OUTFILE}\")\n",
    "else:\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
